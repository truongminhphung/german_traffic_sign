{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-01T08:13:58.554755Z","iopub.execute_input":"2021-11-01T08:13:58.555358Z","iopub.status.idle":"2021-11-01T08:13:58.560099Z","shell.execute_reply.started":"2021-11-01T08:13:58.555321Z","shell.execute_reply":"2021-11-01T08:13:58.559191Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2021-11-01T08:13:51.805248Z","iopub.execute_input":"2021-11-01T08:13:51.805509Z","iopub.status.idle":"2021-11-01T08:13:52.501765Z","shell.execute_reply.started":"2021-11-01T08:13:51.805481Z","shell.execute_reply":"2021-11-01T08:13:52.500915Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport glob\nfrom sklearn.model_selection import train_test_split\nimport shutil\nimport csv\nfrom tensorflow.keras.models import Sequential, load_model, Model\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\nfrom tensorflow.keras.callbacks import ModelCheckpoint","metadata":{"execution":{"iopub.status.busy":"2021-11-01T09:49:01.303471Z","iopub.execute_input":"2021-11-01T09:49:01.304205Z","iopub.status.idle":"2021-11-01T09:49:01.309156Z","shell.execute_reply.started":"2021-11-01T09:49:01.304164Z","shell.execute_reply":"2021-11-01T09:49:01.308139Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"## Split the folders","metadata":{}},{"cell_type":"code","source":"def split(data_path,train,validation,split_size=0.2):\n    folders = os.listdir(data_path)\n    for f in folders:\n        fullpath = os.path.join(data_path,f)\n        image = glob.glob(os.path.join(fullpath,'*.png'))\n       \n        x_train,x_val = train_test_split(image,test_size = split_size)\n        print(\"folder name\",f,len(x_train))\n       \n        for x in x_train:\n         #   print(x)\n            path_to_folder = os.path.join(train,f)\n           \n            if not os.path.isdir(path_to_folder):\n                os.makedirs(path_to_folder)\n            shutil.copy(x,path_to_folder)\n       \n        for y in x_val:\n            path_to_folder = os.path.join(validation,f)\n            if not os.path.isdir(path_to_folder):\n                os.makedirs(path_to_folder)\n            shutil.copy(y,path_to_folder)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T08:14:15.802684Z","iopub.execute_input":"2021-11-01T08:14:15.803284Z","iopub.status.idle":"2021-11-01T08:14:15.810992Z","shell.execute_reply.started":"2021-11-01T08:14:15.803251Z","shell.execute_reply":"2021-11-01T08:14:15.810144Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data_path = \"/kaggle/input/gtsrb-german-traffic-sign/train\"\nif not os.path.isdir('/kaggle/working/Training'):\n    os.mkdir('/kaggle/working/Training')\nif not os.path.isdir('/kaggle/working/Validation'):\n    os.mkdir('/kaggle/working/Validation')\n    \ntrain = '/kaggle/working/Training'\nvalidation = '/kaggle/working/Validation'\n## Split train and validation\nsplit(data_path, train, validation, split_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T08:14:15.812661Z","iopub.execute_input":"2021-11-01T08:14:15.815394Z","iopub.status.idle":"2021-11-01T08:17:08.449182Z","shell.execute_reply.started":"2021-11-01T08:14:15.815362Z","shell.execute_reply":"2021-11-01T08:17:08.448241Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Prepare Test Data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/gtsrb-german-traffic-sign/Test.csv\")\ndf['Path'] = df['Path'].str.replace('Test/', '')\ndf.to_csv('/kaggle/working/Test1.csv')\nos.mkdir(\"/kaggle/working/Test\")","metadata":{"execution":{"iopub.status.busy":"2021-11-01T08:23:01.688407Z","iopub.execute_input":"2021-11-01T08:23:01.688961Z","iopub.status.idle":"2021-11-01T08:23:01.768083Z","shell.execute_reply.started":"2021-11-01T08:23:01.688923Z","shell.execute_reply":"2021-11-01T08:23:01.767389Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def prepare_test(path_to_image,path_file):\n\n    with open(path_file,\"r\") as csvfile:\n        r= csv.reader(csvfile,delimiter =',')\n  \n        for i,row in enumerate(r):\n            if i == 0: \n                continue\n            label = row[-2]\n            img_name = row[-1]\n            \n            dest = os.path.join('/kaggle/working/Test/',label)\n            if not os.path.isdir(dest):\n                os.makedirs(dest)\n            \n            to_move = os.path.join(path_to_image,img_name)\n            shutil.copy(to_move,dest)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T08:31:48.901163Z","iopub.execute_input":"2021-11-01T08:31:48.901420Z","iopub.status.idle":"2021-11-01T08:31:48.907425Z","shell.execute_reply.started":"2021-11-01T08:31:48.901390Z","shell.execute_reply":"2021-11-01T08:31:48.906715Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"path_to_image = \"../input/gtsrb-german-traffic-sign/Test\"\npath_file ='/kaggle/working/Test1.csv'\nprepare_test(path_to_image, path_file)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T08:31:49.474978Z","iopub.execute_input":"2021-11-01T08:31:49.475472Z","iopub.status.idle":"2021-11-01T08:32:48.847547Z","shell.execute_reply.started":"2021-11-01T08:31:49.475436Z","shell.execute_reply":"2021-11-01T08:32:48.846811Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"## Generators: train, validation, test","metadata":{}},{"cell_type":"code","source":"def create_generators():\n    train_datagen = ImageDataGenerator(\n            rescale=1./255,\n            shear_range=0.1, # Shear angle\n            zoom_range=0.2, # go from 0.8 to 1.2\n            width_shift_range=0.1,\n            height_shift_range=0.1,\n            rotation_range=10 # Degrees\n    )\n    validation_datagen = ImageDataGenerator(rescale=1./255)\n    test_datagen = ImageDataGenerator(rescale=1./255)\n    train_generator = train_datagen.flow_from_directory(\n            '/kaggle/working/Training',\n            target_size=(32, 32),\n            batch_size=32,\n            class_mode='categorical')\n    validation_generator = validation_datagen.flow_from_directory(\n            '/kaggle/working/Validation',\n            target_size=(32, 32),\n            batch_size=32,\n            class_mode='categorical')\n    test_generator = test_datagen.flow_from_directory(\n            '/kaggle/working/Test',\n            target_size=(32, 32),\n            batch_size=32,\n            class_mode='categorical')\n    return (train_generator,validation_generator,test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T08:46:14.319348Z","iopub.execute_input":"2021-11-01T08:46:14.319974Z","iopub.status.idle":"2021-11-01T08:46:14.326763Z","shell.execute_reply.started":"2021-11-01T08:46:14.319928Z","shell.execute_reply":"2021-11-01T08:46:14.325937Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=(30, 30, 3)))\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(rate=0.5))\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(rate=0.5))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(rate=0.5))\nmodel.add(Dense(43, activation='softmax'))\n\n#Compilation of the model\nmodel.compile(\n    loss='categorical_crossentropy', \n    optimizer='adam', \n    metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T09:01:00.718864Z","iopub.execute_input":"2021-11-01T09:01:00.719220Z","iopub.status.idle":"2021-11-01T09:01:00.802092Z","shell.execute_reply.started":"2021-11-01T09:01:00.719183Z","shell.execute_reply":"2021-11-01T09:01:00.801353Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-01T09:01:06.510586Z","iopub.execute_input":"2021-11-01T09:01:06.511121Z","iopub.status.idle":"2021-11-01T09:01:06.523206Z","shell.execute_reply.started":"2021-11-01T09:01:06.511086Z","shell.execute_reply":"2021-11-01T09:01:06.522304Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# os.mkdir('/kaggle/working/model')\npath_to_save_model = '/kaggle/working/model'\nchkpt_saver = ModelCheckpoint(\n    path_to_save_model, monitor='val_accuracy',\n    mode ='max',save_best_only= True,\n    save_freq='epoch',verbose = 1\n    )\n\ntrain_generator,validation_generator,test_generator = create_generators()\n\nhistory = model.fit(train_generator, epochs=50, batch_size=32, \n                    validation_data=validation_generator, callbacks=[chkpt_saver])","metadata":{"execution":{"iopub.status.busy":"2021-11-01T09:07:18.612225Z","iopub.execute_input":"2021-11-01T09:07:18.612478Z","iopub.status.idle":"2021-11-01T09:39:49.183561Z","shell.execute_reply.started":"2021-11-01T09:07:18.612450Z","shell.execute_reply":"2021-11-01T09:39:49.182840Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"model = load_model(path_to_save_model)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T09:43:01.456124Z","iopub.execute_input":"2021-11-01T09:43:01.456377Z","iopub.status.idle":"2021-11-01T09:43:02.295365Z","shell.execute_reply.started":"2021-11-01T09:43:01.456349Z","shell.execute_reply":"2021-11-01T09:43:02.294649Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"print(\"validation set\")\nmodel.evaluate(validation_generator)\nprint(\"test set\")\nmodel.evaluate(test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T09:43:25.046772Z","iopub.execute_input":"2021-11-01T09:43:25.047364Z","iopub.status.idle":"2021-11-01T09:43:36.154108Z","shell.execute_reply.started":"2021-11-01T09:43:25.047326Z","shell.execute_reply":"2021-11-01T09:43:36.153349Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"train_1_fnames = os.listdir('/kaggle/working/Training/1')\ntrain_2_fnames = os.listdir('/kaggle/working/Training/2')\n\nprint(train_1_fnames[:10])\nprint(train_2_fnames[:10])","metadata":{"execution":{"iopub.status.busy":"2021-11-01T09:46:00.493789Z","iopub.execute_input":"2021-11-01T09:46:00.494242Z","iopub.status.idle":"2021-11-01T09:46:00.503918Z","shell.execute_reply.started":"2021-11-01T09:46:00.494205Z","shell.execute_reply":"2021-11-01T09:46:00.503174Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing intermediate representations","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport random\nfrom tensorflow.keras.preprocessing.image import img_to_array, load_img\n\n%matplotlib inline\n\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n# Let's define a new Model that will take an image as input, and will output\n# intermediate representations for all layers in the previous model after\n# the first.\nsuccessive_outputs = [layer.output for layer in model.layers[1:]]\n\nvisualization_model = Model(inputs = model.input, outputs = successive_outputs)\n\nsign1_files = [os.path.join('/kaggle/working/Training/1', f) for f in train_1_fnames]\nsign2_files = [os.path.join('/kaggle/working/Training/2', f) for f in train_2_fnames]\n\nimg_path = random.choice(sign1_files + sign2_files)\nimg = load_img(img_path, target_size=(30, 30))  # this is a PIL image\n\nx   = img_to_array(img)                          \nx   = x.reshape((1,) + x.shape)                  \n\n# Rescale by 1/255\nx /= 255.0\n\n# Let's run our image through our network, thus obtaining all\n# intermediate representations for this image.\nsuccessive_feature_maps = visualization_model.predict(x)\n\n# These are the names of the layers, so can have them as part of our plot\nlayer_names = [layer.name for layer in model.layers]\n\n\n# Now let's display our representations\nfor layer_name, feature_map in zip(layer_names, successive_feature_maps):\n  \n  if len(feature_map.shape) == 4:\n    \n    n_features = feature_map.shape[-1]  # number of features in the feature map\n    size       = feature_map.shape[ 1]  # feature map shape (1, size, size, n_features)\n    \n    # We will tile our images in this matrix\n    display_grid = np.zeros((size, size * n_features))\n    \n    #-------------------------------------------------\n    # Postprocess the feature to be visually palatable\n    #-------------------------------------------------\n    for i in range(n_features):\n      x  = feature_map[0, :, :, i]\n      x -= x.mean()\n      x /= x.std ()\n      x *=  64\n      x += 128\n      x  = np.clip(x, 0, 255).astype('uint8')\n      display_grid[:, i * size : (i + 1) * size] = x # Tile each filter into a horizontal grid\n\n    #-----------------\n    # Display the grid\n    #-----------------\n\n    scale = 20. / n_features\n    plt.figure( figsize=((scale * n_features), scale) )\n    plt.title ( layer_name )\n    plt.grid  ( False )\n    plt.imshow( display_grid, aspect='auto', cmap='viridis' )","metadata":{"execution":{"iopub.status.busy":"2021-11-01T09:53:27.731355Z","iopub.execute_input":"2021-11-01T09:53:27.731661Z","iopub.status.idle":"2021-11-01T09:53:28.863109Z","shell.execute_reply.started":"2021-11-01T09:53:27.731623Z","shell.execute_reply":"2021-11-01T09:53:28.862367Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-01T09:54:20.885604Z","iopub.execute_input":"2021-11-01T09:54:20.885858Z","iopub.status.idle":"2021-11-01T09:54:20.896946Z","shell.execute_reply.started":"2021-11-01T09:54:20.885832Z","shell.execute_reply":"2021-11-01T09:54:20.896186Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## Plot the training/validation accuracy","metadata":{}},{"cell_type":"code","source":"#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nacc      = history.history[     'accuracy' ]\nval_acc  = history.history[ 'val_accuracy' ]\nloss     = history.history[    'loss' ]\nval_loss = history.history['val_loss' ]\n\nepochs   = range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     acc )\nplt.plot  ( epochs, val_acc )\nplt.title ('Training and validation accuracy')\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     loss )\nplt.plot  ( epochs, val_loss )\nplt.title ('Training and validation loss'   )","metadata":{"execution":{"iopub.status.busy":"2021-11-01T09:55:26.087286Z","iopub.execute_input":"2021-11-01T09:55:26.087672Z","iopub.status.idle":"2021-11-01T09:55:26.468854Z","shell.execute_reply.started":"2021-11-01T09:55:26.087633Z","shell.execute_reply":"2021-11-01T09:55:26.467649Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":"## Quantization aware training","metadata":{}},{"cell_type":"code","source":"!pip install -q tensorflow-model-optimization","metadata":{"execution":{"iopub.status.busy":"2021-11-01T10:03:45.090611Z","iopub.execute_input":"2021-11-01T10:03:45.091350Z","iopub.status.idle":"2021-11-01T10:03:53.823486Z","shell.execute_reply.started":"2021-11-01T10:03:45.091309Z","shell.execute_reply":"2021-11-01T10:03:53.822640Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"import tensorflow_model_optimization as tfmot\n\nquantize_model = tfmot.quantization.keras.quantize_model\n\n# q_aware stands for for quantization aware.\nq_aware_model = quantize_model(model)\n\n#Compilation of the model\nq_aware_model.compile(\n    loss='categorical_crossentropy', \n    optimizer='adam', \n    metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T10:04:10.694319Z","iopub.execute_input":"2021-11-01T10:04:10.694624Z","iopub.status.idle":"2021-11-01T10:04:13.313077Z","shell.execute_reply.started":"2021-11-01T10:04:10.694589Z","shell.execute_reply":"2021-11-01T10:04:13.312343Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"q_aware_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-01T10:04:29.937209Z","iopub.execute_input":"2021-11-01T10:04:29.937469Z","iopub.status.idle":"2021-11-01T10:04:29.952063Z","shell.execute_reply.started":"2021-11-01T10:04:29.937437Z","shell.execute_reply":"2021-11-01T10:04:29.951240Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"q_aware_model.fit(train_generator, epochs=2, batch_size=32, \n                    validation_data=validation_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T10:06:54.974058Z","iopub.execute_input":"2021-11-01T10:06:54.974311Z","iopub.status.idle":"2021-11-01T10:08:17.591594Z","shell.execute_reply.started":"2021-11-01T10:06:54.974281Z","shell.execute_reply":"2021-11-01T10:08:17.590885Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"print(\"validation set\")\nq_aware_model.evaluate(validation_generator)\nprint(\"test set\")\nq_aware_model.evaluate(test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T10:11:56.564815Z","iopub.execute_input":"2021-11-01T10:11:56.565506Z","iopub.status.idle":"2021-11-01T10:12:07.543206Z","shell.execute_reply.started":"2021-11-01T10:11:56.565467Z","shell.execute_reply":"2021-11-01T10:12:07.542565Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\nconverter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\ntflite_qaware_model = converter.convert()","metadata":{"execution":{"iopub.status.busy":"2021-11-01T10:12:42.761823Z","iopub.execute_input":"2021-11-01T10:12:42.762358Z","iopub.status.idle":"2021-11-01T10:12:45.861132Z","shell.execute_reply.started":"2021-11-01T10:12:42.762320Z","shell.execute_reply":"2021-11-01T10:12:45.860337Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"len(tflite_qaware_model)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T10:13:20.691964Z","iopub.execute_input":"2021-11-01T10:13:20.692234Z","iopub.status.idle":"2021-11-01T10:13:20.697434Z","shell.execute_reply.started":"2021-11-01T10:13:20.692204Z","shell.execute_reply":"2021-11-01T10:13:20.696775Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"markdown","source":"## Without quantization","metadata":{}},{"cell_type":"code","source":"converter = tf.lite.TFLiteConverter.from_keras_model(model)\ntflite_model = converter.convert()\nlen(tflite_model)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T10:14:54.844109Z","iopub.execute_input":"2021-11-01T10:14:54.844359Z","iopub.status.idle":"2021-11-01T10:14:56.101019Z","shell.execute_reply.started":"2021-11-01T10:14:54.844330Z","shell.execute_reply":"2021-11-01T10:14:56.100326Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"with open(\"tflite_qaware_model.tflite\", 'wb') as f:\n    f.write(tflite_qaware_model)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T10:16:58.166289Z","iopub.execute_input":"2021-11-01T10:16:58.166851Z","iopub.status.idle":"2021-11-01T10:16:58.171717Z","shell.execute_reply.started":"2021-11-01T10:16:58.166810Z","shell.execute_reply":"2021-11-01T10:16:58.170621Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}